{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh-MgyQM2Qw9"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The U-Net model is a simple fully  convolutional neural network that is used for binary segmentation i.e foreground and background pixel-wise classification. Mainly, it consists of two parts. \n",
        "\n",
        "*   Contracting Path: we apply a series of conv layers and downsampling layers  (max-pooling) layers to reduce the spatial size \n",
        "*   Expanding Path: we apply a series of upsampling layers to reconstruct the spatial size of the input. \n",
        "\n",
        "The two parts are connected using a concatenation layers among different levels. This allows learning different features at different levels. At the end we have a simple conv 1x1 layer to reduce the number of channels to 1. \n",
        "\n",
        "\n",
        "![alt text](https://blog.playment.io/wp-content/uploads/2018/03/Screen-Shot-2018-09-05-at-3.00.03-PM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LisvDshzevQ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdeDl5HO0QsY"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import imageio\n",
        "import scipy.misc\n",
        "import os\n",
        "from PIL import Image\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from scipy.ndimage import distance_transform_edt as distance\n",
        "import tensorflow.keras.optimizers as opt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model as ldmd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, Conv2DTranspose, Concatenate, BatchNormalization, UpSampling2D\n",
        "from keras.layers import  Dropout, Activation\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "import cv2\n",
        "\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "# See if you need to mount the drive or something else\n",
        "from google.colab import drive\n",
        "drive.mount('./drive')\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "from random import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "bj_9UkU9OEcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r ./drive/MyDrive/colab/data4test_256.zip ./drive/MyDrive/colab/data4test"
      ],
      "metadata": {
        "id": "BcQiO4ZWW-gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tavQ2-MJ0x9E"
      },
      "source": [
        "# Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8tq55g677wp"
      },
      "outputs": [],
      "source": [
        "\n",
        "def trainImage_generator(files, batch_size = 32, sz = (256, 256)):\n",
        "  \n",
        "  while True: \n",
        "    \n",
        "    #extract a random batch \n",
        "    batch = np.random.choice(files, size = batch_size)    \n",
        "    \n",
        "    #variables for collecting batches of inputs and outputs \n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "    # batch_z = []\n",
        "    \n",
        "    \n",
        "    for f in batch:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #get the masks. Note that masks are png files \n",
        "        mask = Image.open(f'./drive/MyDrive/colab/data4test/label/{f[:-3]}'+\"png\")\n",
        "        mask = np.array(mask)\n",
        "\n",
        "\n",
        "        #preprocess the mask \n",
        "        # mask[mask >= 2] = 0 \n",
        "        # mask[mask != 0 ] = 1\n",
        "        \n",
        "\n",
        "\n",
        "        #preprocess the raw images \n",
        "        # raw = Image.open(f'syntheticData/data/{f}')\n",
        "        # raw = raw.resize(sz)\n",
        "        # raw = np.array(raw)\n",
        "\n",
        "        rawMat = sio.loadmat(f'./drive/MyDrive/colab/data4test/data/{f}')\n",
        "        xData = np.array(rawMat['vxSample'])\n",
        "        yData = np.array(rawMat['vySample'])\n",
        "\n",
        "        ImgSize = xData.shape\n",
        "\n",
        "        input_image = np.stack((xData,yData,np.zeros(xData.shape)), -1)\n",
        "        # input_mask = np.stack((mask,mask,mask), -1)\n",
        "\n",
        "\n",
        "        # input_mask = tf.convert_to_tensor(input_mask, np.float32)\n",
        "        # input_image = tf.convert_to_tensor(input_image, np.float32)\n",
        "\n",
        "        # # rotation in 30Â° steps\n",
        "        # if random.random() > 0.5:\n",
        "        #   rot_factor = tf.cast(tf.random.uniform(shape=[], maxval=12, dtype=tf.int32), tf.float32)\n",
        "        #   angle = np.pi/12*rot_factor\n",
        "        #   input_image = tfa.image.rotate(input_image, angle)\n",
        "        #   input_mask = tfa.image.rotate(input_mask, angle)\n",
        "\n",
        "\n",
        "        # if random.random() > 0.5:\n",
        "        #     # use original image to preserve high resolution\n",
        "        #     input_image = tf.image.central_crop(input_image, 0.75)\n",
        "        #     input_mask = tf.image.central_crop(input_mask, 0.75)\n",
        "\n",
        "        # resize\n",
        "        input_image = cv2.resize(input_image, sz)\n",
        "        input_mask = cv2.resize(mask, sz)\n",
        "\n",
        "        # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
        "        # input_mask = cv2.morphologyEx(input_mask,cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        # flipping random horizontal or vertical\n",
        "        if random.random() > 0.5:\n",
        "            input_image = cv2.flip(input_image,0)\n",
        "            input_mask = cv2.flip(input_mask,0)\n",
        "        if random.random() > 0.5:\n",
        "            input_image = cv2.flip(input_image,1)\n",
        "            input_mask = cv2.flip(input_mask,1)\n",
        "\n",
        "        # if random.random() > 0.5:\n",
        "        #     xData = np.fliplr(xData)\n",
        "        #     yData = np.fliplr(yData)\n",
        "        #     mask = np.fliplr(mask)\n",
        "        # if random.random() > 0.5:\n",
        "        #     xData = np.flipud(xData)\n",
        "        #     yData = np.flipud(yData)\n",
        "        #     mask = np.flipud(mask)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # input_mask = tf.image.rgb_to_grayscale(input_mask)\n",
        "\n",
        "        input_image = np.asarray(input_image)\n",
        "        input_mask = np.asarray(input_mask)\n",
        "        input_mask[input_mask != 0 ] = 1\n",
        "\n",
        "        batch_x.append(input_image)\n",
        "        batch_y.append(input_mask)\n",
        "        # batch_z.append(f)\n",
        "\n",
        "\n",
        "    #preprocess a batch of images and masks \n",
        "    # batch_x = np.array(batch_x)/255.\n",
        "    batch_x = np.array(batch_x)\n",
        "    batch_y = np.array(batch_y)\n",
        "    batch_y = np.expand_dims(batch_y,3)\n",
        "\n",
        "\n",
        "\n",
        "    yield (batch_x, batch_y)     \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def validImage_generator(files, batch_size = 32, sz = (256, 256)):\n",
        "  \n",
        "  while True: \n",
        "    \n",
        "    #extract a random batch \n",
        "    batch = np.random.choice(files, size = batch_size)    \n",
        "    \n",
        "    #variables for collecting batches of inputs and outputs \n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "    # batch_z = []\n",
        "    \n",
        "    \n",
        "    for f in batch:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #get the masks. Note that masks are png files \n",
        "        mask = Image.open(f'./drive/MyDrive/colab/data4test/label/{f[:-3]}'+\"png\")\n",
        "        mask = np.array(mask)\n",
        "\n",
        "\n",
        "        #preprocess the mask \n",
        "        # mask[mask >= 2] = 0 \n",
        "        # mask[mask != 0 ] = 1\n",
        "        \n",
        "\n",
        "\n",
        "        #preprocess the raw images \n",
        "        # raw = Image.open(f'syntheticData/data/{f}')\n",
        "        # raw = raw.resize(sz)\n",
        "        # raw = np.array(raw)\n",
        "\n",
        "        rawMat = sio.loadmat(f'./drive/MyDrive/colab/data4test/data/{f}')\n",
        "        xData = np.array(rawMat['vxSample'])\n",
        "        yData = np.array(rawMat['vySample'])\n",
        "\n",
        "        ImgSize = xData.shape\n",
        "\n",
        "        input_image = np.stack((xData,yData,np.zeros(xData.shape)), -1)\n",
        "        # input_mask = np.stack((mask,mask,mask), -1)\n",
        "\n",
        "\n",
        "        # input_mask = tf.convert_to_tensor(input_mask, np.float32)\n",
        "        # input_image = tf.convert_to_tensor(input_image, np.float32)\n",
        "\n",
        "        # # rotation in 30Â° steps\n",
        "        # if random.random() > 0.5:\n",
        "        #   rot_factor = tf.cast(tf.random.uniform(shape=[], maxval=12, dtype=tf.int32), tf.float32)\n",
        "        #   angle = np.pi/12*rot_factor\n",
        "        #   input_image = tfa.image.rotate(input_image, angle)\n",
        "        #   input_mask = tfa.image.rotate(input_mask, angle)\n",
        "\n",
        "\n",
        "        # if random.random() > 0.5:\n",
        "        #     # use original image to preserve high resolution\n",
        "        #     input_image = tf.image.central_crop(input_image, 0.75)\n",
        "        #     input_mask = tf.image.central_crop(input_mask, 0.75)\n",
        "\n",
        "        # resize\n",
        "        input_image = cv2.resize(input_image, sz)\n",
        "        input_mask = cv2.resize(mask, sz)\n",
        "\n",
        "        # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
        "        # input_mask = cv2.morphologyEx(input_mask,cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        input_image = np.asarray(input_image)\n",
        "        input_mask = np.asarray(input_mask)\n",
        "        input_mask[input_mask != 0 ] = 1\n",
        "\n",
        "        batch_x.append(input_image)\n",
        "        batch_y.append(input_mask)\n",
        "        # batch_z.append(f)\n",
        "\n",
        "\n",
        "    #preprocess a batch of images and masks \n",
        "    # batch_x = np.array(batch_x)/255.\n",
        "    batch_x = np.array(batch_x)\n",
        "    batch_y = np.array(batch_y)\n",
        "    batch_y = np.expand_dims(batch_y,3)\n",
        "\n",
        "\n",
        "\n",
        "    yield (batch_x, batch_y)   \n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvwbmS-YTHEZ"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "all_files = os.listdir('./drive/MyDrive/colab/data4test/data/')\n",
        "shuffle(all_files)\n",
        "\n",
        "split = int(0.85 * len(all_files))\n",
        "\n",
        "#split into training and testing\n",
        "train_files = all_files[0:split]\n",
        "test_files  = all_files[split:]\n",
        "\n",
        "train_generator = trainImage_generator(train_files, batch_size = batch_size)\n",
        "test_generator  = validImage_generator(test_files, batch_size = batch_size)\n",
        "final_test_generator = validImage_generator(all_files, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn_bdWgIuRHD"
      },
      "outputs": [],
      "source": [
        "x, y= next(train_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnuNW20FeupL"
      },
      "outputs": [],
      "source": [
        "plt.axis('off')\n",
        "img = x[0]\n",
        "msk = y[0].squeeze()\n",
        "\n",
        "\n",
        "\n",
        "msk = np.stack((msk,)*3, axis=-1)\n",
        "\n",
        "print(msk.shape)\n",
        "print(img.shape)\n",
        "\n",
        "\n",
        "vel_img = np.sqrt(np.power(img[:,:,0],2)+np.power(img[:,:,1],2))\n",
        "\n",
        "# vel_img = np.stack((vel_img,vel_img,vel_img), axis = -1)\n",
        "plt.imshow( np.concatenate([img, msk], axis = 1))\n",
        "# plt.imshow(msk)\n",
        "plt.show()\n",
        "\n",
        "# plt.imshow(img)\n",
        "# plt.show\n",
        "\n",
        "\n",
        "# print(z[0])\n",
        "# print(\"img:\",img)\n",
        "# print(\"msk:\",msk)\n",
        "# print(\"img*msk:\",img*msk)\n",
        "\n",
        "\n",
        "mdict = {\"vxSample\": img[:,:,0], \"vySample\": img[:,:,1],\"mask\":msk}\n",
        "sio.savemat(\"testimage.mat\",mdict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raXLOfBk1pLV"
      },
      "source": [
        "# IoU metric\n",
        "\n",
        "The intersection over union (IoU) metric is a simple metric used to evaluate the performance of a segmentation algorithm. Given two masks $y_{true}, y_{pred}$ we evaluate \n",
        "\n",
        "$$IoU = \\frac{y_{true} \\cap y_{pred}}{y_{true} \\cup y_{pred}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJLriYXX1oZU"
      },
      "outputs": [],
      "source": [
        "def mean_iou(y_true, y_pred):\n",
        "    yt0 = K.cast(y_true[:,:,:,0],'float32')\n",
        "    yp0 = K.cast(y_pred[:,:,:,0] > 0.5, 'float32')\n",
        "    inter = tf.math.count_nonzero(tf.logical_and(tf.equal(yt0, 1), tf.equal(yp0, 1)))\n",
        "    union = tf.math.count_nonzero(tf.add(yt0, yp0))\n",
        "    iou = tf.where(tf.equal(union, 0), 1., tf.cast(inter/union, 'float32'))\n",
        "    return iou\n",
        "\n",
        "# def mean_iou(y_true, y_pred):\n",
        "\n",
        "def IoULoss(y_true, y_pred, smooth=1e-6):\n",
        "    \n",
        "    #flatten label and prediction tensors\n",
        "    inputs = K.flatten(K.cast(y_pred,'float32'))\n",
        "    targets = K.flatten(K.cast(y_true,'float32'))\n",
        "    \n",
        "\n",
        "    intersection = K.sum(targets*inputs)\n",
        "    total = K.sum(targets) + K.sum(inputs)\n",
        "    union = total - intersection\n",
        "    \n",
        "    IoU = (intersection + smooth) / (union + smooth)\n",
        "    return 1 - IoU\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ1Zw7qaBpzz"
      },
      "source": [
        "# Dice Related Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvf7_LLABpJJ"
      },
      "outputs": [],
      "source": [
        "def DiceLoss(targets, inputs, smooth=1e-6):\n",
        "    \n",
        "    #flatten label and prediction tensors\n",
        "    inputs = K.flatten(K.cast(inputs,'float32'))\n",
        "    targets = K.flatten(K.cast(targets,'float32'))\n",
        "    \n",
        "    intersection = K.sum(targets*inputs)\n",
        "    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
        "    return 1 - dice\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def DiceBCELoss(targets, inputs, smooth=1e-6):    \n",
        "       \n",
        "    #flatten label and prediction tensors\n",
        "    inputs = K.flatten(K.cast(inputs,'float32'))\n",
        "    targets = K.flatten(K.cast(targets,'float32'))\n",
        "    \n",
        "    BCE =  tf.keras.losses.binary_crossentropy(targets, inputs)\n",
        "    intersection = K.sum(targets*inputs)   \n",
        "    dice_loss = 1 - (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
        "    Dice_BCE = BCE + dice_loss\n",
        "    \n",
        "    return Dice_BCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nLgpj_BBa6S"
      },
      "source": [
        "# Boundary Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUI_bJWbBZs_"
      },
      "outputs": [],
      "source": [
        "def calc_dist_map(seg):\n",
        "    res = np.zeros_like(seg)\n",
        "    posmask = seg.astype(bool)\n",
        "\n",
        "    if posmask.any():\n",
        "        negmask = ~posmask\n",
        "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def calc_dist_map_batch(y_true):\n",
        "    y_true_numpy = y_true.numpy()\n",
        "    return np.array([calc_dist_map(y)\n",
        "                     for y in y_true_numpy]).astype(np.float32)\n",
        "\n",
        "\n",
        "def surface_loss_keras(y_true, y_pred):\n",
        "    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n",
        "                                     inp=[y_true],\n",
        "                                     Tout=tf.float32)\n",
        "    multipled = y_pred * y_true_dist_map\n",
        "    return K.mean(multipled)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combination of loss function"
      ],
      "metadata": {
        "id": "erFlnI1CrGgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def BCEDiceIOU(targets, inputs, smooth=1e-6):    \n",
        "       \n",
        "    #flatten label and prediction tensors\n",
        "    inputs = K.flatten(K.cast(inputs,'float32'))\n",
        "    targets = K.flatten(K.cast(targets,'float32'))\n",
        "    \n",
        "    BCE =  tf.keras.losses.binary_crossentropy(targets, inputs)\n",
        "    intersection = K.sum(targets*inputs)   \n",
        "    dice_loss = 1 - (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
        "\n",
        "\n",
        "    total = K.sum(targets) + K.sum(inputs)\n",
        "    union = total - intersection\n",
        "    \n",
        "    IoU = 1 - (intersection + smooth) / (union + smooth)\n",
        "\n",
        "    Dice_BCE_IoU = BCE + dice_loss + IoU\n",
        "    \n",
        "    return Dice_BCE_IoU"
      ],
      "metadata": {
        "id": "gERTq70BrM86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other loss function"
      ],
      "metadata": {
        "id": "lmq3ZHb_otXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "def confusion(y_true, y_pred):\n",
        "    smooth=1\n",
        "    y_pred_pos = K.clip(y_pred, 0, 1)\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "    y_pos = K.clip(y_true, 0, 1)\n",
        "    y_neg = 1 - y_pos\n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg) \n",
        "    prec = (tp + smooth)/(tp+fp+smooth)\n",
        "    recall = (tp+smooth)/(tp+fn+smooth)\n",
        "    return prec, recall\n",
        "\n",
        "def tp(y_true, y_pred):\n",
        "    smooth = 1\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    tp = (K.sum(y_pos * y_pred_pos) + smooth)/ (K.sum(y_pos) + smooth) \n",
        "    return tp \n",
        "\n",
        "def tn(y_true, y_pred):\n",
        "    smooth = 1\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos \n",
        "    tn = (K.sum(y_neg * y_pred_neg) + smooth) / (K.sum(y_neg) + smooth )\n",
        "    return tn \n",
        "\n",
        "def tversky(y_true, y_pred):\n",
        "    smooth = 1\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    y_pred = K.flatten(K.cast(y_pred,'float32'))\n",
        "    y_true = K.flatten(K.cast(y_true,'float32'))\n",
        "    return 1 - tversky(y_true,y_pred)\n",
        "\n",
        "def focal_tversky(y_true,y_pred):\n",
        "    y_pred = K.flatten(K.cast(y_pred,'float32'))\n",
        "    y_true = K.flatten(K.cast(y_true,'float32'))\n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)"
      ],
      "metadata": {
        "id": "CiHEkstQ858L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "160g6Ex41r-2"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hONrrUbW9CM_"
      },
      "outputs": [],
      "source": [
        "def unet(sz = (256, 256, 3)):\n",
        "  x = Input(sz)\n",
        "  inputs = x\n",
        "  \n",
        "  #down sampling \n",
        "  f = 8\n",
        "  layers = []\n",
        "  \n",
        "  for i in range(0, 6):\n",
        "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "    layers.append(x)\n",
        "    x = MaxPooling2D() (x)\n",
        "    f = f*2\n",
        "  ff2 = 64 \n",
        "  \n",
        "  #bottleneck \n",
        "  j = len(layers) - 1\n",
        "  x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "  x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "  x = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (x)\n",
        "  x = Concatenate(axis=3)([x, layers[j]])\n",
        "  j = j -1 \n",
        "  \n",
        "  #upsampling \n",
        "  for i in range(0, 5):\n",
        "    ff2 = ff2//2\n",
        "    f = f // 2 \n",
        "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "    x = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (x)\n",
        "    x = Concatenate(axis=3)([x, layers[j]])\n",
        "    j = j -1 \n",
        "    \n",
        "  \n",
        "  #classification \n",
        "  x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "  x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "  outputs = Conv2D(1, 1, activation='sigmoid') (x)\n",
        "  \n",
        "\n",
        "  # Decay learning rate\n",
        "  initial_learning_rate = 0.0005\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "          initial_learning_rate,\n",
        "          decay_steps=800,\n",
        "          decay_rate=0.96,\n",
        "          staircase=True)\n",
        "\n",
        "  #model creation \n",
        "  model = Model(inputs=[inputs], outputs=[outputs])\n",
        "  rmsprop_optimizer = opt.RMSprop(learning_rate=lr_schedule, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "  model.compile(optimizer = rmsprop_optimizer, loss = tversky_loss, metrics = [mean_iou])\n",
        "  # model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = [mean_iou])\n",
        "\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67Fyeczk_zzh"
      },
      "outputs": [],
      "source": [
        "model = unet()\n",
        "# model.load_weights(\"./drive/MyDrive/colab/unet.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7QY8rgO1zUU"
      },
      "source": [
        "# Callbacks\n",
        "\n",
        "Simple functions to save the model at each epoch and show some predictions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfqXmNuc9lWZ"
      },
      "outputs": [],
      "source": [
        "def build_callbacks():\n",
        "        checkpointer = ModelCheckpoint(filepath='./drive/MyDrive/colab/unet.h5', verbose=0, save_best_only=True, save_weights_only=True)\n",
        "        callbacks = [checkpointer, PlotLearning()]\n",
        "        return callbacks\n",
        "\n",
        "# inheritance for training process plot \n",
        "class PlotLearning(keras.callbacks.Callback):\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.acc = []\n",
        "        self.val_acc = []\n",
        "        #self.fig = plt.figure()\n",
        "        self.logs = []\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.acc.append(logs.get('mean_iou'))\n",
        "        self.val_acc.append(logs.get('val_mean_iou'))\n",
        "        self.i += 1\n",
        "        print('i=',self.i,'loss=',logs.get('loss'),'val_loss=',logs.get('val_loss'),'mean_iou=',logs.get('mean_iou'),'val_mean_iou=',logs.get('val_mean_iou'))\n",
        "        \n",
        "        f = open('./drive/MyDrive/colab/loss.txt', 'a')\n",
        "        f.write(str(logs.get('loss'))+'\\n')\n",
        "        f.close()\n",
        "\n",
        "        f = open('./drive/MyDrive/colab/val_loss.txt', 'a')\n",
        "        f.write(str(logs.get('val_loss'))+'\\n')\n",
        "        f.close()\n",
        "\n",
        "        f = open('./drive/MyDrive/colab/mean_iou.txt', 'a')\n",
        "        f.write(str(logs.get('mean_iou'))+'\\n')\n",
        "        f.close()\n",
        "\n",
        "        f = open('./drive/MyDrive/colab/val_mean_iou.txt', 'a')\n",
        "        f.write(str(logs.get('val_mean_iou'))+'\\n')\n",
        "        f.close()\n",
        "\n",
        "\n",
        "        #choose a random test image and preprocess\n",
        "        path = np.random.choice(test_files)\n",
        "        # raw = Image.open(f'syntheticData/trainingData/{path}')\n",
        "        # raw = np.array(raw.resize((256, 256)))/255.\n",
        "        # raw = raw[:,:,0:3]\n",
        "\n",
        "        rawMat = sio.loadmat(f'./drive/MyDrive/colab/data4test/data/{path}')\n",
        "        xData = np.array(rawMat['vxSample'])\n",
        "        imgX = Image.fromarray(xData)\n",
        "        xData = np.array(imgX.resize((256,256)))\n",
        "        yData = np.array(rawMat['vySample'])\n",
        "        imgY = Image.fromarray(yData)\n",
        "        yData = np.array(imgY.resize((256,256)))\n",
        "        raw = np.stack((xData, yData, np.zeros(xData.shape)), axis = -1)\n",
        "\n",
        "\n",
        "        \n",
        "        #predict the mask \n",
        "        pred = model.predict(np.expand_dims(raw, 0))\n",
        "        \n",
        "        #mask post-processing \n",
        "        msk  = pred.squeeze()\n",
        "        msk = np.stack((msk,)*3, axis=-1)\n",
        "        msk[msk >= 0.5] = 1 \n",
        "        msk[msk < 0.5] = 0 \n",
        "        \n",
        "        groundTruth = Image.open(f'./drive/MyDrive/colab/data4test/label/{path[:-3]}png')\n",
        "\n",
        "        #show the mask and the segmented image \n",
        "        combined = np.concatenate([raw, msk*255, raw* msk], axis = 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(combined)\n",
        "        plt.show()\n",
        "        print(path[:-9])\n",
        "        plt.axis('off')\n",
        "        plt.imshow(groundTruth)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU6SPuVY8Mdc"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MXGinNg9Wjj"
      },
      "outputs": [],
      "source": [
        "train_steps = len(train_files) //batch_size\n",
        "test_steps = len(test_files) //batch_size\n",
        "\n",
        "\n",
        "\n",
        "model.fit(train_generator, \n",
        "                    epochs = 400, steps_per_epoch = train_steps,validation_data = test_generator, validation_steps = test_steps,\n",
        "                    callbacks = build_callbacks(), verbose = 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O5zCKBr8OZ1"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S17rew7Vqk5e"
      },
      "outputs": [],
      "source": [
        "#Test file\n",
        "\n",
        "test_files = sorted(os.listdir('./drive/MyDrive/colab/data4test/data'))\n",
        "groundTruth_files = sorted(os.listdir('./drive/MyDrive/colab/data4test/label'))\n",
        "\n",
        "#split into training and testing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#variables for collecting batches of inputs and outputs \n",
        "batch_x = []\n",
        "batch_y = []\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0, len(test_files)):\n",
        "# for i in range(0, 1):\n",
        "  rawtTest = sio.loadmat('./drive/MyDrive/colab/data4test/data/'+test_files[i])\n",
        "  rawGround = Image.open('./drive/MyDrive/colab/data4test/label/'+groundTruth_files[i]).resize((256,256))\n",
        "  xData = np.array(rawtTest['vxSample'])\n",
        "  imgX = Image.fromarray(xData)\n",
        "  xData = np.array(imgX.resize((256,256)))\n",
        "  yData = np.array(rawtTest['vySample'])\n",
        "  imgY = Image.fromarray(yData)\n",
        "  yData = np.array(imgY.resize((256,256)))\n",
        "  raw = np.stack((xData, yData, np.zeros(xData.shape)), axis = -1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # raw = Image.open('385_33.png')\n",
        "  # raw = np.array(raw.resize((256, 256)))/255.\n",
        "  # raw = raw[:,:,0:3]\n",
        "\n",
        "  #predict the mask \n",
        "  pred = model.predict(np.expand_dims(raw, 0))\n",
        "\n",
        "  #mask post-processing \n",
        "  msk  = pred.squeeze()\n",
        "  msk = np.stack((msk,)*3, axis=-1)\n",
        "  msk[msk >= 0.5] = 1 \n",
        "  msk[msk < 0.5] = 0 \n",
        "\n",
        "  #show the mask and the segmented image \n",
        "  combined = np.concatenate([raw, msk, raw*msk], axis = 1)\n",
        "\n",
        "  savePath = test_files[i]\n",
        "  imageio.imwrite('./drive/MyDrive/colab/data4test/predict/'+savePath[:-4]+'.png', msk)\n",
        "  # pred_Image = Image.fromarray(msk)\n",
        "  # pred_Image.save('data4test/predict/'+savePath[:-4]+'predict.png')\n",
        "\n",
        "  plt.axis('off')\n",
        "  plt.imshow(combined)\n",
        "  # plt.imshow(raw)\n",
        "  # plt.imshow(msk)\n",
        "  # plt.imshow(rawGround)\n",
        "  plt.show()\n",
        "\n",
        "  plt.axis('off')\n",
        "  # plt.imshow(combined)\n",
        "  # plt.imshow(raw)\n",
        "  # plt.imshow(msk)\n",
        "  plt.imshow(rawGround)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfoO80D4uYAj"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "1.   http://deeplearning.net/tutorial/unet.html\n",
        "2.   https://github.com/ldenoue/keras-unet\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}